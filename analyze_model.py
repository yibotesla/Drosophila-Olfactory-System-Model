#!/usr/bin/env python3
"""
æ¨¡å‹è®¾è®¡ç›®çš„éªŒè¯åˆ†æ
Analyze whether the model achieves its design goals
"""

import numpy as np
from src.model import DrosophilaOlfactoryModel
from src.odor_dataset import OdorDataset
from src.evaluator import ModelEvaluator

def analyze_model():
    print("=" * 70)
    print("æœè‡å—…è§‰ç³»ç»Ÿæ¨¡å‹ - è®¾è®¡ç›®çš„éªŒè¯åˆ†æ")
    print("Drosophila Olfactory Model - Design Goal Verification")
    print("=" * 70)
    
    # åˆ›å»ºæ¨¡å‹
    model = DrosophilaOlfactoryModel(
        n_pn=50, n_kc=2000, n_mbon=1,
        sparsity=0.05, learning_rate=0.1, seed=42
    )
    dataset = OdorDataset(n_features=50)
    evaluator = ModelEvaluator(model)
    
    print("\n" + "=" * 70)
    print("1. ç¨€ç–ç¼–ç éªŒè¯ (Sparse Coding)")
    print("=" * 70)
    
    odor = dataset.generate_prototype("test", seed=100)
    _, kc_activation = model.predict(odor)
    
    active_count = int(kc_activation.sum())
    expected_active = int(model.n_kc * model.sparsity)
    sparsity_actual = active_count / model.n_kc * 100
    
    print(f"   KC æ€»æ•°: {model.n_kc}")
    print(f"   è®¾å®šç¨€ç–åº¦: {model.sparsity * 100:.1f}%")
    print(f"   å®é™…æ¿€æ´» KC æ•°: {active_count}")
    print(f"   æœŸæœ›æ¿€æ´» KC æ•°: {expected_active}")
    print(f"   å®é™…ç¨€ç–åº¦: {sparsity_actual:.2f}%")
    print(f"   âœ… ç¨€ç–ç¼–ç æ­£å¸¸å·¥ä½œ" if abs(active_count - expected_active) <= 1 else "   âŒ ç¨€ç–ç¼–ç å¼‚å¸¸")
    
    print("\n" + "=" * 70)
    print("2. æ¨¡å¼åˆ†ç¦»éªŒè¯ (Pattern Separation)")
    print("=" * 70)
    
    # ç”Ÿæˆå¤šå¯¹ç›¸ä¼¼æ°”å‘³
    separations = []
    for i in range(20):
        base = dataset.generate_prototype(f"base_{i}", seed=i*10)
        # åˆ›å»º90%ç›¸ä¼¼çš„å˜ä½“
        variant = base.copy()
        change_idx = np.random.choice(50, 5, replace=False)
        variant[change_idx] = np.random.uniform(0, 1, 5)
        
        sep = evaluator.compute_pattern_separation(base, variant)
        separations.append(sep)
    
    avg_input_overlap = np.mean([s['input_overlap'] for s in separations])
    avg_kc_overlap = np.mean([s['kc_overlap'] for s in separations])
    avg_separation_ratio = np.mean([s['separation_ratio'] for s in separations])
    
    print(f"   æµ‹è¯•æ ·æœ¬æ•°: 20 å¯¹ç›¸ä¼¼æ°”å‘³")
    print(f"   å¹³å‡è¾“å…¥é‡å åº¦: {avg_input_overlap:.4f}")
    print(f"   å¹³å‡ KC é‡å åº¦: {avg_kc_overlap:.4f}")
    print(f"   é‡å åº¦é™ä½: {(avg_input_overlap - avg_kc_overlap) / avg_input_overlap * 100:.1f}%")
    print(f"   å¹³å‡åˆ†ç¦»æ¯”: {avg_separation_ratio:.4f}")
    
    if avg_kc_overlap < avg_input_overlap:
        print(f"   âœ… æ¨¡å¼åˆ†ç¦»æœ‰æ•ˆ (KC é‡å åº¦ < è¾“å…¥é‡å åº¦)")
    else:
        print(f"   âŒ æ¨¡å¼åˆ†ç¦»æ— æ•ˆ")
    
    print("\n" + "=" * 70)
    print("3. è”æƒ³å­¦ä¹ éªŒè¯ (Associative Learning)")
    print("=" * 70)
    
    model.reset_weights(clear_history=True)
    
    odor_a = dataset.generate_prototype("A", seed=100)
    odor_b = dataset.generate_prototype("B", seed=200)
    
    # è®­ç»ƒå‰å“åº”
    response_before_a, _ = model.predict(odor_a)
    response_before_b, _ = model.predict(odor_b)
    
    print(f"\n   è®­ç»ƒå‰å“åº”:")
    print(f"   - æ°”å‘³ A: {response_before_a[0]:.4f}")
    print(f"   - æ°”å‘³ B: {response_before_b[0]:.4f}")
    
    # å¯¹æ°”å‘³ A è¿›è¡ŒåŒæ¶è®­ç»ƒ
    print(f"\n   æ‰§è¡ŒåŒæ¶è®­ç»ƒ (æ°”å‘³ A, 5æ¬¡)...")
    for _ in range(5):
        model.train_aversive(odor_a, strength=1.0)
    
    # è®­ç»ƒåå“åº”
    response_after_a, _ = model.predict(odor_a)
    response_after_b, _ = model.predict(odor_b)
    
    print(f"\n   è®­ç»ƒåå“åº”:")
    print(f"   - æ°”å‘³ A: {response_after_a[0]:.4f} (å˜åŒ–: {response_after_a[0] - response_before_a[0]:.4f})")
    print(f"   - æ°”å‘³ B: {response_after_b[0]:.4f} (å˜åŒ–: {response_after_b[0] - response_before_b[0]:.4f})")
    
    # è®¡ç®—åŒºåˆ†æŒ‡æ•°
    di_a = evaluator.compute_discrimination_index(response_before_a, response_after_a)
    di_b = evaluator.compute_discrimination_index(response_before_b, response_after_b)
    
    print(f"\n   åŒºåˆ†æŒ‡æ•°:")
    print(f"   - æ°”å‘³ A (è®­ç»ƒ): {di_a:.4f}")
    print(f"   - æ°”å‘³ B (æœªè®­ç»ƒ): {di_b:.4f}")
    
    if response_after_a[0] < response_before_a[0]:
        print(f"   âœ… åŒæ¶å­¦ä¹ æœ‰æ•ˆ (è®­ç»ƒæ°”å‘³å“åº”é™ä½)")
    else:
        print(f"   âŒ åŒæ¶å­¦ä¹ æ— æ•ˆ")
    
    print("\n" + "=" * 70)
    print("4. å­¦ä¹ ç‰¹å¼‚æ€§éªŒè¯ (Learning Specificity)")
    print("=" * 70)
    
    relative_change_b = abs(response_after_b[0] - response_before_b[0]) / response_before_b[0] * 100
    
    print(f"   æœªè®­ç»ƒæ°”å‘³å“åº”å˜åŒ–: {relative_change_b:.2f}%")
    
    if relative_change_b < 10:
        print(f"   âœ… å­¦ä¹ ç‰¹å¼‚æ€§è‰¯å¥½ (æœªè®­ç»ƒæ°”å‘³å˜åŒ– < 10%)")
    else:
        print(f"   âš ï¸ å­¦ä¹ ç‰¹å¼‚æ€§ä¸€èˆ¬ (å­˜åœ¨ä¸€å®šæ³›åŒ–)")
    
    print("\n" + "=" * 70)
    print("5. ä¹˜æ³•å­¦ä¹ è§„åˆ™éªŒè¯ (Multiplicative Learning)")
    print("=" * 70)
    
    model.reset_weights(clear_history=True)
    
    # æµ‹è¯•è¾¹ç•Œå‡é€Ÿæ•ˆæœ
    weights_history = []
    weights_history.append(model.weights_kc_mbon.mean())
    
    for i in range(20):
        model.train_aversive(odor_a, strength=1.0)
        weights_history.append(model.weights_kc_mbon.mean())
    
    # è®¡ç®—å‰5æ¬¡å’Œå5æ¬¡çš„å¹³å‡å˜åŒ–
    early_changes = [weights_history[i] - weights_history[i+1] for i in range(5)]
    late_changes = [weights_history[i] - weights_history[i+1] for i in range(15, 20)]
    
    avg_early = np.mean(early_changes)
    avg_late = np.mean(late_changes)
    
    print(f"   å‰5æ¬¡è®­ç»ƒå¹³å‡æƒé‡å˜åŒ–: {avg_early:.6f}")
    print(f"   å5æ¬¡è®­ç»ƒå¹³å‡æƒé‡å˜åŒ–: {avg_late:.6f}")
    print(f"   å˜åŒ–å‡é€Ÿæ¯”: {avg_early / avg_late:.2f}x")
    
    if avg_late < avg_early:
        print(f"   âœ… ä¹˜æ³•è§„åˆ™æœ‰æ•ˆ (æƒé‡æ¥è¿‘è¾¹ç•Œæ—¶æ›´æ–°å‡é€Ÿ)")
    else:
        print(f"   âŒ ä¹˜æ³•è§„åˆ™æ— æ•ˆ")
    
    print("\n" + "=" * 70)
    print("6. å­¦ä¹ å†å²è®°å½•éªŒè¯ (Learning History)")
    print("=" * 70)
    
    history = model.get_learning_history()
    print(f"   è®°å½•çš„è®­ç»ƒäº‹ä»¶æ•°: {len(history)}")
    print(f"   æœŸæœ›çš„è®­ç»ƒäº‹ä»¶æ•°: 20")
    
    if len(history) == 20:
        print(f"   âœ… å­¦ä¹ å†å²è®°å½•å®Œæ•´")
        print(f"   æœ€åä¸€æ¬¡è®­ç»ƒ:")
        print(f"   - ç±»å‹: {history[-1]['type']}")
        print(f"   - å¼ºåº¦: {history[-1]['strength']}")
        print(f"   - æƒé‡å˜åŒ–: {history[-1]['weight_change']:.6f}")
    else:
        print(f"   âŒ å­¦ä¹ å†å²è®°å½•ä¸å®Œæ•´")
    
    print("\n" + "=" * 70)
    print("7. æ³›åŒ–èƒ½åŠ›éªŒè¯ (Generalization)")
    print("=" * 70)
    
    model.reset_weights(clear_history=True)
    
    # è®­ç»ƒä¸€ä¸ªæ°”å‘³
    trained_odor = dataset.generate_prototype("trained", seed=500)
    for _ in range(5):
        model.train_aversive(trained_odor, strength=1.0)
    
    # æµ‹è¯•ä¸åŒå™ªå£°æ°´å¹³çš„å˜ä½“
    noise_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]
    responses = []
    
    for noise in noise_levels:
        if noise == 0:
            resp, _ = model.predict(trained_odor)
            responses.append(resp[0])
        else:
            variants = dataset.generate_variants(trained_odor, n_samples=10, noise_level=noise, seed=600)
            variant_responses = [model.predict(v)[0][0] for v in variants]
            responses.append(np.mean(variant_responses))
    
    print(f"   å™ªå£°æ°´å¹³ -> å¹³å‡å“åº”:")
    for noise, resp in zip(noise_levels, responses):
        print(f"   - {noise:.1f}: {resp:.4f}")
    
    # æ£€æŸ¥æ³›åŒ–æ¢¯åº¦
    if responses[0] < responses[-1]:
        print(f"   âœ… æ³›åŒ–æ¢¯åº¦æ­£å¸¸ (å™ªå£°å¢åŠ  -> å“åº”æ¢å¤)")
    else:
        print(f"   âš ï¸ æ³›åŒ–æ¢¯åº¦å¼‚å¸¸")
    
    print("\n" + "=" * 70)
    print("8. åºåˆ—åŒ–å¾€è¿”éªŒè¯ (Serialization Round-Trip)")
    print("=" * 70)
    
    # ä¿å­˜å½“å‰æ¨¡å‹
    json_str = model.to_json()
    
    # æ¢å¤æ¨¡å‹
    restored_model = DrosophilaOlfactoryModel.from_json(json_str)
    
    # éªŒè¯
    original_response, _ = model.predict(trained_odor)
    restored_response, _ = restored_model.predict(trained_odor)
    
    weights_match = np.allclose(model.weights_kc_mbon, restored_model.weights_kc_mbon)
    response_match = np.allclose(original_response, restored_response)
    history_match = len(model.get_learning_history()) == len(restored_model.get_learning_history())
    
    print(f"   æƒé‡çŸ©é˜µä¸€è‡´: {'âœ…' if weights_match else 'âŒ'}")
    print(f"   å“åº”è¾“å‡ºä¸€è‡´: {'âœ…' if response_match else 'âŒ'}")
    print(f"   å­¦ä¹ å†å²ä¸€è‡´: {'âœ…' if history_match else 'âŒ'}")
    
    if weights_match and response_match and history_match:
        print(f"   âœ… åºåˆ—åŒ–å¾€è¿”éªŒè¯é€šè¿‡")
    else:
        print(f"   âŒ åºåˆ—åŒ–å¾€è¿”éªŒè¯å¤±è´¥")
    
    print("\n" + "=" * 70)
    print("æ€»ç»“ (Summary)")
    print("=" * 70)
    
    results = {
        "ç¨€ç–ç¼–ç ": abs(active_count - expected_active) <= 1,
        "æ¨¡å¼åˆ†ç¦»": avg_kc_overlap < avg_input_overlap,
        "è”æƒ³å­¦ä¹ ": response_after_a[0] < response_before_a[0],
        "å­¦ä¹ ç‰¹å¼‚æ€§": relative_change_b < 15,
        "ä¹˜æ³•å­¦ä¹ è§„åˆ™": avg_late < avg_early,
        "å­¦ä¹ å†å²è®°å½•": len(history) == 20,
        "æ³›åŒ–èƒ½åŠ›": responses[0] < responses[-1],
        "åºåˆ—åŒ–å¾€è¿”": weights_match and response_match and history_match,
    }
    
    passed = sum(results.values())
    total = len(results)
    
    print(f"\n   éªŒè¯é¡¹ç›®: {total}")
    print(f"   é€šè¿‡: {passed}")
    print(f"   å¤±è´¥: {total - passed}")
    print(f"\n   è¯¦ç»†ç»“æœ:")
    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   - {name}: {status}")
    
    print(f"\n   æ€»ä½“è¯„ä¼°: ", end="")
    if passed == total:
        print("ğŸ‰ æ¨¡å‹å®Œå…¨è¾¾åˆ°è®¾è®¡ç›®çš„!")
    elif passed >= total * 0.8:
        print("âœ… æ¨¡å‹åŸºæœ¬è¾¾åˆ°è®¾è®¡ç›®çš„")
    elif passed >= total * 0.6:
        print("âš ï¸ æ¨¡å‹éƒ¨åˆ†è¾¾åˆ°è®¾è®¡ç›®çš„")
    else:
        print("âŒ æ¨¡å‹æœªè¾¾åˆ°è®¾è®¡ç›®çš„")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    analyze_model()
